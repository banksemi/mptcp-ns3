{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b64351e2-2a42-451b-9901-fa88a694bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 라이브러리 \n",
    "import copy\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "throughput_interval = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "043d5221-3fc1-4b9b-82d9-8df90ef128f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커널 로그를 기반으로 패킷 송수신 내용 추출\n",
    "def read(file_name, throughput_analysis=True):\n",
    "    # 파일 읽기\n",
    "    with open(file_name) as json_file:\n",
    "        message = json_file.read()\n",
    "        \n",
    "    # 정규식 추출\n",
    "    # 예시: tcp_header_size,-544,507,48\n",
    "    # 데이터 이름, Flow id, 시간, 값\n",
    "    p = re.compile('''([a-z\\_0-9]+),([\\-0-9]+),([0-9]+),([0-9]+)''')\n",
    "    result = p.finditer(message)\n",
    "    \n",
    "    temp = []\n",
    "    for r in result:\n",
    "        key = str(r.group(1))\n",
    "        flow_id = int(r.group(2))\n",
    "        flow_time = int(r.group(3))\n",
    "        value = int(r.group(4))\n",
    "        temp.append([flow_time, flow_id, key, value])\n",
    "\n",
    "    # [time, flow_id, key, value] 형태의 테이블 생성\n",
    "    # 그러나 MPTCP가 아닌 다른 플로우 데이터도 함께 존재함\n",
    "    table = pd.DataFrame(temp, columns=['time', 'flow_id', 'key', 'value'])\n",
    "    \n",
    "    # 가장 많은 데이터를 보낸 3개의 플로우를 제외한 나머지 제거\n",
    "    table_not_included_meta_flow = table[table['flow_id'] != 0]\n",
    "    remove_id = table_not_included_meta_flow['flow_id'].value_counts().keys()[2:]\n",
    "    table = table.loc[table['flow_id'].isin(remove_id) == False]\n",
    "    \n",
    "    # 첫 번째 subflow 찾기 (=가장 처음으로 로그가 발생한 플로우)\n",
    "    temp = table[table['flow_id'] != 0] # MPTCP 레벨이 아닌 것 중\n",
    "    subflow_id = temp.sort_values([\"time\"], ascending=[True])\n",
    "    first_flow = subflow_id.iloc[0]['flow_id']\n",
    "    \n",
    "    # 각 flow별로 네임태그 지정\n",
    "    table.loc[table['flow_id'] == 0, 'flow_id'] = 'mptcp'\n",
    "    table.loc[table['flow_id'] == first_flow, 'flow_id'] = 'sub1'\n",
    "    table.loc[(table['flow_id'] != 'mptcp') & (table['flow_id'] != 'sub1') , 'flow_id'] = 'sub2'\n",
    "    \n",
    "    # 시간 값 정규화 (커널 시간 -> FLow 시작 시간)\n",
    "    min_time = table.loc[:,\"time\"].min() # 기준 값 설정\n",
    "    \n",
    "    # 250hz의 세분성\n",
    "    table.loc[:,\"time\"] = (table.loc[:,\"time\"] - min_time) / 250\n",
    "    \n",
    "    table.name = file_name\n",
    "    \n",
    "    # Throughput 및 총 전송량 추가\n",
    "    total_throughput = []\n",
    "    \n",
    "    # range 함수는 int만 지원\n",
    "    bins = [i / 1000 for i in range(0, 60000, int(throughput_interval * 1000))]\n",
    "\n",
    "    option = []\n",
    "    for subflow in ['sub1', 'sub2']:\n",
    "        flow = select(table, subflow, \"send\")\n",
    "        transmission = flow.groupby(pd.cut(flow['time'], bins=bins)).sum()\n",
    "        y = [i / 1024 / 1024 for i in list(transmission['value'])]\n",
    "\n",
    "        flow = select(table, subflow, \"retransmission\")\n",
    "        retransmission = flow.groupby(pd.cut(flow['time'], bins=bins)).sum()\n",
    "\n",
    "        sent = 0\n",
    "        for i in range(0, len(list(transmission['value']))):\n",
    "            sent += transmission['value'].iloc[i]\n",
    "            option.append([bins[i], subflow, 'throughput', y[i] / throughput_interval])\n",
    "            option.append([bins[i], subflow, 'retransmission', retransmission['value'].iloc[i]])\n",
    "            option.append([bins[i], subflow, 'total_bytes', sent])\n",
    "    \n",
    "    # total_bytes for mptcp level\n",
    "    flow = table.loc[(table['key'] == 'mptcp_send') & (table['value'] >= 10000)].copy()\n",
    "    flow['value'] -= 10000\n",
    "    transmission_redundant = flow.groupby(pd.cut(flow['time'], bins=bins)).sum()\n",
    "    \n",
    "    flow = table.loc[(table['key'] == 'mptcp_send') & (table['value'] < 10000)]\n",
    "    transmission_real = flow.groupby(pd.cut(flow['time'], bins=bins)).sum()\n",
    "    \n",
    "    sent = 0\n",
    "    sent_included_redundant = 0\n",
    "    for i in range(0, len(list(transmission['value']))):\n",
    "        sent += transmission_real['value'].iloc[i]\n",
    "        sent_included_redundant += transmission_real['value'].iloc[i]\n",
    "        sent_included_redundant += transmission_redundant['value'].iloc[i]\n",
    "        option.append([bins[i], 'mptcp', 'total_bytes', sent])\n",
    "        option.append([bins[i], 'mptcp', 'total_bytes_included_redundant', sent_included_redundant])\n",
    "        \n",
    "    temp = pd.DataFrame(option, columns=['time', 'flow_id', 'key', 'value'])\n",
    "    table = pd.concat([table, temp])\n",
    "    table = table.loc[table['key'] != 'mptcp_send']\n",
    "    \n",
    "    return table\n",
    "\n",
    "# 특정 subflow의 데이터를 선택하는 함수\n",
    "def select(table, subflow, key):\n",
    "    flow = table.loc[table[\"flow_id\"] == subflow]\n",
    "    flow = flow.loc[flow['key'] == key]\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe27958-8bd3-41cc-b022-9094bd0f2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(table, file_name):\n",
    "    for subflow in table[\"flow_id\"].unique():\n",
    "        table2 = table.loc[table[\"flow_id\"] == subflow]\n",
    "        for key in table2[\"key\"].unique():\n",
    "            table3 = table2.loc[table2['key'] == key]\n",
    "            base_path = \"saves/\" + file_name\n",
    "            if os.path.isdir(base_path) == False:\n",
    "                os.mkdir(base_path)\n",
    "            table3.to_csv(base_path + \"/\" + subflow + \"_\" + key + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "730bc51f-64fc-4257-badd-ef185227a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(default, \"그림3_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8e7fc6f9-6d11-4a04-ba3d-5204737ceefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"logs/\"\n",
    "default = read(prefix + \"default.txt\");\n",
    "redundant = read(prefix + \"redundant.txt\");\n",
    "redundant00085 = read(prefix + \"redundant00085.txt\");\n",
    "redundant00165 = read(prefix + \"redundant00165.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc364167-cb90-4004-843e-95a8c454cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(default, \"그림3_default\")\n",
    "save(redundant, \"그림4_redundant\")\n",
    "save(redundant00165, \"그림5_redundant_5MBps_0.016간격\")\n",
    "save(redundant00085, \"그림5_redundant_5MBps_0.008간격\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463cb24-137d-4883-9c01-1ec22ef0cab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
